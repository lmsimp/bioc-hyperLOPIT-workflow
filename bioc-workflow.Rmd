---
title: "A Bioconductor Workflow for Processing and Analysing Spatial Proteomics Data"
author: "Lisa Breckels"
output: html_document
---

```{r env, echo=FALSE}
library("BiocStyle")
suppressPackageStartupMessages(library("MSnbase"))
suppressPackageStartupMessages(library("pRoloc"))
```

# Introduction

Quantitative mass spectrometry based spatial proteomics involves
elaborate, expensive and time consuming experimental procedures and
considerable effort is invested in the generation of such
data. Multiple research groups have described a variety of approaches
to establish high quality proteome-wide datasets. However, data
analysis is as critical as data production for reliable and insightful
biological interpretation. Here, we walk the reader through a typical
pipeline for the analysis of such data using several Bioconductor
packages for the R statistical programming environment.

The main package to analyse protein localisation data is
`r Biocpkg("pRoloc")`, which offers a set of dedicated functions for the
analysis of such data. `r Biocpkg("pRoloc")` itself relies on `r Biocpkg("MSnbase")` to
manipulate and process quantitative proteomics data. Many other
packages are used by `r Biocpkg("pRoloc")` for clustering, classification and
visualisation.

In this workflow, we will describe how to prepare the spatial
proteomics data starting from a spreadsheet containing quantitative
mass spectrometry data. We will focus on a recent pluripotent mouse
embryonic stem cells experiment [@hyper]. Additional annotated and
pre-formatted datasets from various species are readily available in
the `r Biocexptpkg("pRolocdata")` package.

Installation of Bioconductor package is documented in details on the
[Bioconductor installation help page](http://bioconductor.org/install/#install-bioconductor-packages). This
procedure is also applicable to any packages, from
[CRAN](https://cran.r-project.org/) as well as GitHub. Once a package
has been installed, it needs to be loaded for it functionality become
available in the R session; this is done with the `library` function.

If you have questions about this workflow in particular, or about
other Bioconductor packages in general, they a best asked on the
[Bioconductor support site](https://support.bioconductor.org/)
following the
[posting guidelines](http://www.bioconductor.org/help/support/posting-guide/). Questions
can be tagged with specific package names or keywords. For more
general information about mass spectrometry and proteomics, the
readers are invited to read the `r Biocexptpkg("RforProteomics")`
package vignettes and associated papers [@Gatto:2014;@Gatto2015]. 


# Reading and handling mass-spectrometry based proteomics data

## The use-case: prediction sub-cellular localisation in pluripotent embryonic mouse stem cells

As a use-case we analyse a recent high-throughput spatial proteomics
dataset from pluripotent mouse embryonic stem cells (E14TG2a)
[@hyper]. The data was generated using hyperplexed LOPIT (hyperLOPIT),
an improved method relying on better sub-cellular fractionation and
more acurate quantitation, leading to more reliable classification of
protein localisation across the whole sub-cellular space. The method
uses an elaborate sub-cellular fractionation scheme, enabled by the
use of Tandem Mass Tag (TMT) [Thompson:2003] 10-plex and application
of the MS data acquisition technique named synchronous precursor
selection MS$^3$ (SPS)-MS$^3$ [@McAlister:2014], for TMT
quantification with high accuracy and precision. Three biological
replicates were generated from the E14TG2a experiment, the first was
to target low density fractions and the second and third were to
emphasis separation of the denser organelles. The intersect of
replicates 1 and 2 was treated as a 20-plex dataset for the analysis
discussed in the manuscript [@hyper] as it has been shown that
combining replicates across from different gradients can increase
spatial resolution [@trotter]. The combination of replicates resulted
in 5032 proteins common in both experiments. Before combination, the
two replicates were separately normalised by sum across the 10
channels (i.e. such that the sum of each protein's intensity is 1),
for each replicate respectively. Normalisation is an essential part of
data processing and several methods are available in 
`r Biocpkg("MSnbase")`. The normalisation desired in this specific case
would be obtained with the a call to the `normalise` method.

The combination of data can also be performed effectively in 
`r Biocpkg("MSnbase")` as detailed in the dedicated *Combining MSnSet
instances* section of the `r Biocpkg("MSnbase")`
[tutorial vignette](http://bioconductor.org/packages/release/bioc/vignettes/MSnbase/inst/doc/MSnbase-demo.pdf).

## The infrastructure: `r Biocpkg("pRoloc")` and `r Biocpkg("MSnbase")` in Bioconductor

To make use of the full functionality of the `r Biocpkg("pRoloc")` software one is required to import their data into R as a `MSnSet` instance. The `MSnSet` is a dedicated data structure for the efficient manipulation and processing of mass spectrometry and proteomics data in R. Figure 1 illustrates a simplified view of the `MSnSet` structure; there exists 3 key slots (1) the `exprs` slot for storing the quantitation data, (2) the `fData` slot for storing the feature meta-data, and finally (3) the `pData` slot for storing the sample meta-data. 
![**Figure 1.** Simplified representation of the `MSnSet` data structure (reproduced with permission from the `r Biocpkg("MSnbase")` vignette)](./Figures/msnset.png)

There are a number of ways to import quantitation data and create a `MSnSet` instance and all methods are described in the `r Biocpkg("MSnbase")` [input/output capabilities vignette](http://bioconductor.org/packages/release/bioc/vignettes/MSnbase/inst/doc/MSnbase-io.pdf). One suggested simple method is to use the function `readMSnSet2` in `r Biocpkg("MSnbase")`. The function takes a single spreadsheet as input and extracts the columns containing the quantitation data, as identified by the argument `ecol`, to create the expression data, while the other columns in the spreadsheet are appended to the feature meta-data slot. 
By example, in the code chunk below we read in the `csv` spreadsheet containing the quantitation data from the intersect of replicates 1 and 2 of the mouse map [@hyper], using the `readMSnSet2` function. The data is as available online with the manuscript (see tab 2 of the `xlsx` supplementary data set 1 in [@hyper]) and also as both a `csv` and `MSnSet` object in the Bioconductor `r Biocexptpkg("pRolocdata")` data package. 

To use the `readMSnSet2` function, as a minimum one must specify the file path to the data and which columns of the spreadsheet contain quantitation data. The `getEcols` function exists to help users identify which columns of the spreadsheet that contain the quantitation data. The spreadsheet of E14TG2a data; "hyperLOPIT-SIData-ms3-rep12-intersect.csv", contains 5032 proteins common across the 2 biological replicates for the respective 2 x 10-plex reporter tags, along with associated feature meta-data such as protein markers, protein description, number of quantified peptides etc. The spreadsheet contains two headers, with the second header containing information about where the quantitation data is stored. We can display the names of the second header by calling the `getEcols` function with the argument `n = 2`, to specify that we wish to display the column names of the second header. It is now easy for one to identify that the quantitation data is located in columns 8 to 27. It is also possible to pass the optional argument `fnames` to indicate which column to use as the labels by which to identify each protein in the sample. Here, we use `fnames = 1` to use the Uniprot identifiers contained in the first column of the spreadsheet.


```{r makeMSnSet, message=FALSE, warning=FALSE}
library("MSnbase")

f0 <- dir(system.file("extdata", package = "pRolocdata"), full.names = TRUE, 
          pattern = "hyperLOPIT-SIData-ms3-rep12-intersect.csv")

getEcols(f0, split = ",", n = 2)

lopit2016 <- readMSnSet2(f0, ecol = c(8:27), fnames = 1, skip = 1, 
                         stringsAsFactors = FALSE)


## Note: arguments can be passed to read.table and friends using ...
## here we use skip = 1 to tell readMSnSet2 to skip 1 line before
## beginning to read data.

## Examine the quantitative information for first 5 proteins 
exprs(lopit2016)[1:5, ]
```

As briefly mentioned above, the quantitation data is stored in the `exprs` slot of the `MSnSet` and can be accessed by `exprs(lopit2016)`. The feature meta-data is stored in the `fData` slot and can be accessed by `fData(lopit2016)`. When using `readMSnSet2`, automatically, everything that is not defined as quantitation data by `ecol` or the feature names by `fnames` is deposited to the `fData` slot. As we wish to demonstrate the complete analysis of this data we remove the results from the prior analysis described in [@hyper] in the code chunk below. We see the `fData` contains 25 columns describing information such as the number of peptides, associated markers, machine learning results etc. For demonstration in the code chunk below keep the 2nd, 8th and 11th columns which contain the Uniprot entry names and two different marker sets to use an input for machine learning analyses (see sections on markers and subsequent sections).

```{r removefData}
fvarLabels(lopit2016)
fData(lopit2016) <- fData(lopit2016)[, c(2, 8, 11)]
head(fData(lopit2016))
```


# Quality Control

Data quality is routinely examined through visualisation to verify that sub-cellular niches have been separated along the gradient. Based on De Duve's principle [@DeDuve:1981] proteins that co-localise exhibit similar quantitation profiles across the gradient fractions employed. One approach that has been widely used to visualise and inspect high throughput mass spectrometry-based proteomics data is principal components analysis (PCA). PCA is one of many dimensionality reduction methods, that allow one to effectively summarise multi-dimensional data in to 2 or 3 dimensions to enable visualisation. Very generally, the original continuous multi-dimensional data is transformed into a set of orthogonal components ordered according to the amount of variability that they describe. The `plot2D` method in `r Biocpkg("pRoloc")` allows one to plot the principal components (PCs) of a dataset against one another, by default the first two components are plotted on the x- and y-axis, respectively (the `dims` argument can be used to plot other PCs). If distinct clusters are observed, we assume that there is organellar separation present in the data. In the code chunk below we produce a PCA plot of the mouse stem cell dataset. One point on the plot represents one protein. We can indeed see several distinct protein clusters. Although, plotting the PCs does not give us a hard quantitative measure of separation, it is extremely useful summarising complex experimental information in one figure, to get an simplified overview of the data. 

```{r qcplot, message=FALSE, warning=FALSE}
library('pRoloc')
plot2D(lopit2016, fcol = NULL)
```

# Markers

In the context of spatial proteomics, a marker protein is defined as a well-known resident of a specific sub-cellular niche in a species *and* condition of interest. Applying this to machine learning (ML), and specifically supervised learning, for the task of protein localisation prediction, markers constitute the labelled training data to use as input for a classification analyses. Defining well-known residents, and obtaining labelled training data for ML analyses can be time consuming, but is important to define markers that are representative of the multivariate data space and on which a classifier will be trained and generated. `r Biocpkg("pRoloc")` provides a convenience function, `addMarkers`, to directly add markers to a `MSnSet` object, as demonstrated in the code chunk below. These marker sets can be accessed using the `pRolocmarkers()` function. Marker sets are stored as a simple named vector in R, and originate from in-house user-defined spreadsheets or a set of markers from previous published studies. The marker vectors that can be accessed from `pRolocmarkers` are named vectors and to enable mapping between the markers and the `MSnSet` instance it is required that the `featureNames` of the `MSnSet` instance match the `names` of the marker. The mouse dataset used here has Uniprot IDs stored as the `featureNames` (see `head(featureNames(lopit2016))`) and the names of the vector of the mouse markers (`mmus` markers) are Uniprot entry names (see `head(mrk)` in the code chunk below), therefore it is required we update the `MSnSet` to match the names of the markers, as demonstrated below. It is then possible to match names between the markers and the `MSnSet` instance. We see below that the markers cover many sub-cellular niches, with many niches only containing a few proteins. Depending on the biological question and downstream analyses we may wish the subset these marker classes, this can be done using the `minMarkers` function. In the code chunk below, we demonstrate how to add markers using `pRolocmarkers` function and then visualise these annotations using the `plot2D` function.

```{r addmrkers}
## List available marker sets
pRolocmarkers()

## Use mouse markers
mrk <- pRolocmarkers(species = "mmus")
head(mrk)

## Change featureNames of the MSnSet to match the marker names 
## which are named by Uniprot Entry Name
featureNames(lopit2016) <- make.unique(fData(lopit2016)[, 1])

## Add mouse markers
lopit2016 <- addMarkers(lopit2016, mrk)

## Remove marker sets with < 20 proteins
lopit2016 <- minMarkers(lopit2016, n = 20)
getMarkers(lopit2016, fcol = "markers20")
plot2D(lopit2016, fcol = "markers20", main = "pRolocmarkers for mouse")

## After expert curation
plot2D(lopit2016, fcol = "SVM.marker.set", main = "Curated markers")
```

In general, the Gene Ontology (GO) [@Ashburner:2000], and in particular the cellular compartment (CC) namespace are a good starting point for protein annotation and marker definition. It is important to note however that automatic retrieval of sub-cellular localisation information, from `r Biocpkg("pRoloc")` or elsewhere, is only the beginning in defining a marker set for downstream analyses. Expert curation is vital to check that any annotation added is in the correct context for the the biological question under investigation. In the code chunk above we show the PCA plot output of the mouse dataset with (i) the annotation for mouse pulled from `pRolocmarkers`, and (ii) annotation after expert curation (stored in the `featureData` column called `SVM.marker.set` that was used for a classification analyses in the original data analyses [@hyper]).

# Interactive visualisation



# Novelty Detection

The extraction of sub-cellular protein clusters can be difficult owing to the limited number of marker proteins that exist in databases and elsewhere. Furthermore, given the vast complexity of the cell, automatic annotation retrieval does not always give a full representation of the true sub-cellular diversity in the data. For downstream analyses, such as supervised machine learning, it is desirable to obtain reliable markers that cover as many sub-cellular niches as possible, as these markers are directly used in the training phase of the ML classification. We find that a lack of sub-cellular diversity in the labelled training data leads to prediction errors, as unlabelled instances can only be assigned to a class that exists in the training data [@Breckels:2013]. In such scenarios novelty detection can be useful to identify data-specific sub-cellular groupings such as organelles and protein complexes. The phenotype discovery (phenoDisco) algorithm [@Breckels:2013] is one such method and is available in `r Biocpkg("pRoloc")`. It is an iterative semi-supervised learning method that combines the classification of proteins on existing labelled data with the detection of new clusters. Novelty detection methods are also useful for confirming the presence of known clusters in an unbiased fashion. For example, in [@hyper] the `phenoDisco` algorithm was used to detect the data-specific confirmation and presence of the nucleus and nucleus sub-compartments, as it was expected that nucleus associated clusters existed within the data as the protocol included a separate chromatin-rich fraction to enrich for nuclei. In the code chunk below, we show how to run a series of novelty detection experiments using the `phenoDisco` algorithm on the mouse stem-cell dataset. There are several optional arguments that can be set dependent on the type of biological question of interest. For example, 

- Explain how to use different group sizes for detecting small complexes etc.
- ndims for using >=2 components
- times -> important for convergence
- input markers are different here -> explain choice of pd.markers

```{r pd, eval = FALSE}
## As per the hyperLOPIT paper
pdRes <- phenoDisco(lopit2016, fcol = "phenoDisco.Input", times = 200, 
                    GS = 20, p = 0.05)

```

# Supervised machine learning

Supervised machine learning, also known as classification, is an essential tool for the assignment of proteins to distinct sub-cellular niches. Using a set of labelled training examples i.e. markers, we can train a machine learning classifier to learn a mapping between the data i.e. the quantitative protein profiles, and a known localisation. The trained classifier can then be used to predict the localisation of a protein of unknown localisation, based on its observed protein profile. To date, this method has been extensively used in spatial quantitative proteomics to assign thousands of proteins to distinct sub-cellular niches [@hyper; @Groen:2014; @trotter; @Hall:2009; @Dunkley:2006; @Tan:2009]. 

There are several classification algorithms available in `pRoloc`, which are documented in the dedicated [`pRoloc` Machine learning techniques vignette](http://bioconductor.org/packages/release/bioc/vignettes/pRoloc/inst/doc/pRoloc-ml.pdf). We find the general tendancy to be that it is not the choice of classifier but the proper optimisation of the algorithms parameters that limit the classification results. Before employing a classification algorithm and generating a model on the training data with which to classify our set of unknown residents, one must find the optimal parameters for the algorithm of choice. For example, in the code chunk below we employ the use of a Support Vector Machine (SVM) to learn a classifier on the labelled training data. In the example below, the training data is found in the `featureData` slot in the column called `SVM.marker.set`.

Notes:
- take care of properly setting the model parameters. 
- Wrongly set parameters can have adverse effects 
- how well they represent the multivariate data?
- Parameter optimisation can be conducted in a number of ways. One of the most common is train/test plus 5-fold x-val

```{r loadpdRes, include=FALSE}
pdRes <- lopit2016
load("Data/fusionparams.rda")
```
```{r optimise, eval=FALSE}
w <- table(fData(pdRes)[, "SVM.marker.set"])
w <- 1/w[names(w) != "unknown"]

params <- svmOptimisation(pdRes, fcol = "SVM.marker.set",
                          times = 100, xval = 5,
                          class.weights = w,
                          verbose = TRUE)
```
```{r visualiseOpt}
plot(params)
levelPlot(params)
(best <- getParams(params))
```
```{r classify, eval=TRUE}
svmRes <- svmClassification(pdRes, params,
                            class.weights = w,
                            fcol = "SVM.marker.set")
```



## Transfer learning

# Session information

The function `sessionInfo` provides a summary of all packages and
versions used to generate this document. This enables us to record the
exact state of our session that lead to these exact
results. Conversely, if the script stops working of if it returns
different results, we are in a position to re-generate the original
results using the adequate software versions and retrace changes in
the software that lead to failure and/or different results.

```{r si}
sessionInfo()
```

It is always important to include session information details along
with a
[short reproducible example](http://adv-r.had.co.nz/Reproducibility.html)
highlighting the problem or
[question](https://support.bioconductor.org/) at hand.
